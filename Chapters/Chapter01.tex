% Chapter 1

\chapter{Introduction} % Chapter title

\label{ch:introduction} % For referencing the chapter elsewhere, use \autoref{ch:introduction} 

% Intro text

\begin{flushleft}{\slshape    
Once upon a time statisticians only explored. Then they learned to \\
confirm exactly - to confirm a few things exactly, each under very \\
specific circumstances. As they emphasized exact confirmation, their \\
techniques inevitably became less flexible. The connection of the most \\
used techniques with past insights was weakened. Anything to which \\
a confirmatory procedure was not explicitly attached was decried as \\
'mere descriptive statistics', no matter how much we had learned from it.} \\ \medskip
--- \citeA{tukey1977exploratory}
\end{flushleft}

\bigskip

Consider the following scenario: An educational researcher just finished collecting data for a large grant examining how teacher-student interactions are related to student outcomes. When originally writing up the grant, the researcher had some specific hypotheses grounded in theory that the grant was designed to test. The data set was cleaned and prepped, and the hypotheses were empirically tested. These tests yielded results providing support for some of the original hypotheses, while others were a little less clear. Naturally, the researcher had collected additional variables that may or may not be relevant to the outcome (e.g., teacher and student demographics), and is now interested in performing exploratory data analysis to examine these variables further. However, unlike the original hypotheses, theory does not have strong predictions for these additional variables. Interested in performing a more exploratory study with these data, the researcher now has to make decisions regarding which variables to include, how these variables might be related (linearly, quadratically, etc.), and if potential interactions might be necessary in these exploratory models. How does the researcher proceed?


This situation is becoming more common as there is an increasing number of datasets with a large number of participants, variables, or both, in education and other fields that often deal with multilevel data structures. With this increase of available information, it becomes necessary to be able to efficiently search a large parameter space to identify variables that might have been overlooked to uncover insights and help inform future research. Currently, this practice is typically accomplished in the social sciences ``by hand.'' That is, the researcher in question will run multiple tests from a hypothesis testing framework with different model specifications and combinations of variables in order to determine which are the most important \cite{strobl2009introduction}.


While some argue that exploratory approaches do not need any type of correction as the results are preliminary \cite{schochet2008technical}, performing exploratory data analysis solely with a hypothesis testing framework is still rife with statistical issues regarding the generalizability of such findings. For example, it is easy to blur the lines between what is confirmatory and what is exploratory when confronted with a large dataset with many possible quantitative decisions \cite{wagenmakers2012agenda}. In such situations, there is an increased chance of detecting spurious findings due to the large number of potential researcher degrees of freedom \cite{gelman2014statistical, ioannidis2005most, simmons2011false}. Even seemingly simple choices of what covariates to include or which distribution to specify for the outcome is enough to make researchers come to different conclusions regarding the statistical significance of a given variable when confronted with the same research question \cite{silberzahn2014}.


To address this concern, more emphasis is being placed on replication \cite{osc2014, oscinpress}. Although many participating in this movement stem from social psychology in particular, this movement has also been echoed in other areas where complex multilevel data are commonplace, such as developmental psychology \cite{duncan2014} and education \cite{makel2014facts}. While replicability is a hallmark of good scientific practice \cite{nosek2012scientific}, it is more feasible to implement as a means to control for potential spurious effects caused by a large number of researcher degrees of freedom in some domains more than others \cite{finkelinpress}. In many social psychology lab studies, for example, the preliminary nature of exploratory data analysis can simply be confirmed with the running of additional studies at relatively minimal cost. Studies that are run in settings as complex as a school system unfortunately do not have this luxury. 


What is needed, then, is a more efficient means of exploratory data analysis that can help uncover insight while simultaneously controlling for spurious findings, have the ability to be implemented when theory might not dictate how the model should be specified, handle situations where complex, multilevel data structures are commonplace, and, arguably most important, be something that can be adopted by the average, applied researcher. Given that previous research has focused solely on performing confirmatory and exploratory research from a null hypothesis significance testing perspective \cite{berk2008statistical, finkelinpress}, identifying a potential solution to this problem seems almost infeasible. However, solutions are readily available with a simple, two-step shift in statistical perspective. 

First, focus needs to be placed on predictive modeling (i.e., predicting new observations based on patterns found in previous observations) rather than explanatory modeling (i.e., providing evidence for a hypothesis with significant effects in a given direction). This removes the burden of using existing theory (which may or may not exist) to dictate what should or should not be specified in a given statistical model \cite{shmueli2010explain}. The second step involves utilizing algorithmic methods that assume the data generative mechanism is unknown, rather than adopting a method that relies on the assumption that the data were generated from a given stochastic model \cite{breiman2001statistical}. In other words, instead of assuming that the relation between an outcome and a predictor is a specific function of the given predictor value, its estimated parameter, and random noise, an algorithm treats the functional relation between the predictor and the outcome as unknown and something to be estimated. Algorithmic methods remove the burden of specifying complex function forms, such as non-linear relations or higher order interactions, when attempting to build predictive data models.


Through this shift of perspective, it becomes possible to understand and adopt a popular data mining algorithm known as recursive partitioning to identify subsets of variables that are most related to a given outcome, and what kind of statistical relation it might be. This framework produces a set of binary decision rules based on covariate values in an attempt to create a set of subgroups, or nodes, which are homogeneous with respect to a given outcome \cite{mcardle2013}. This is particularly relevant in the context of multilevel data, where cases or observations are nested (e.g., children nested within classrooms). In these situations, using traditional methods, such as linear regression, can result in an increased chance of detecting significant effects due to the broken statistical assumption of independence \cite{peugh2010practical}. The general recursive partitioning framework, on the other hand, makes no such assumptions, indicating that this method could extend to multilevel data structures with little added complications. And yet despite its potential utility in the social sciences, the implementation of these algorithms in the face of complex, multilevel data structures, is not well understood \cite{mcardle2013}.


The purpose of this dissertation is to evaluate the implementation of two popular recursive partitioning algorithms in the presence of multilevel data structures commonly found in applied educational and psychological contexts. Upon finishing this dissertation, I will be able to conclude whether recursive partitioning is a feasible tool to conduct exploratory data analysis in the presence of multilevel data, and, if so, which underlying algorithm yields the best results. This proposal is structured into five chapters. \autoref{ch:methods} provides a foundational overview of the two popular algorithms under investigation, classification and regression trees (CART) and conditional inference trees (CTREE), as well as their ensemble method (i.e., forest) counterparts. This section also includes a brief overview of statistical terminology relevant to understanding the application of predictive models, such as bias, variance, and model validation. \autoref{ch:previous} covers previous research extending recursive partitioning frameworks to more advanced applications relevant to complex, multilevel data structures. \autoref{ch:problem} outlines unanswered questions when considering the application of both CART or CTREE to multilevel data structures, with a set of hypotheses based on previous research and preliminary simulation results. \autoref{ch:proposal} is the proposal. This section includes how the open questions proposed in \autoref{ch:problem} will be evaluated with a proposed simulation study. Additionally, this section will outline three large, multilevel datasets to be explored with recursive partitioning as well as plans to disseminate a set of best practices for applied researchers interested in these methods for their own research.

